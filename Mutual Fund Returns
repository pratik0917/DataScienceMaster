#Task 1 - Load dataset and check summary statistics
# import libraries
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt


# Code starts here
data = pd.read_csv(path)
print(data.shape)
data.describe()
data.drop('Serial Number',axis=1,inplace=True)

# code ends here



#Task 2 - Hypothesis Testing
#Importing header files
from scipy.stats import chi2_contingency
import scipy.stats as stats

#Critical value 
critical_value = stats.chi2.ppf(q = 0.95, # Find the critical value for 95% confidence*
                      df = 11)   # Df = number of variable categories(in purpose) - 1

# Code starts here
return_rating= data['morningstar_return_rating'].value_counts()
risk_rating = data['morningstar_risk_rating'].value_counts()
print(return_rating.transpose())
print(risk_rating.transpose())
observed = pd.concat([return_rating.transpose(),risk_rating.transpose()],axis = 1,keys= ['return','risk'])
print(observed)
chi2, p, dof, ex=chi2_contingency(observed)

# Code ends here

#Task 3 - Remove correlated features
# Code starts here
correlation = abs(data.corr())
us_correlation=correlation.unstack()
us_correlation.sort_values(ascending=False, inplace=True)
max_correlated=us_correlation[(us_correlation>0.75) & (us_correlation<1)]
#print(max_correlated)
data.drop(['morningstar_rating','portfolio_stocks','category_12','sharpe_ratio_3y'],axis=1,inplace=True)
print(data.columns)


##us_correlation.sort_values(ascending=False,inplace=True)
#print(us_correlation)


#print(corre.head(5))
##correlation=correlation[abs(corre)>0.75]
#print(correlation.head(5))
##us_correlation = correlation.unstack()
##print(us_correlation.head(5))
##us_correlation = sort_value(corre,ascending=False)

# code ends here

#Task 4 - Outlier check!
# Code starts here
fig, (ax_1, ax_2) = plt.subplots(1,2, figsize=(20,10))
data.boxplot(column='price_earning',ax=ax_1)
data.boxplot(column='net_annual_expenses_ratio',ax=ax_2)
# code ends here

#Task 5 - Split the dataset and predictor check !
# import libraries
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score,mean_squared_error

# Code starts here
y=data['bonds_aaa']
data.drop(['bonds_aaa'],axis=1,inplace=True)
X=data[:]

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 3)
lr=LinearRegression()
lr.fit(X_train,y_train)
y_pred=lr.predict(X_test)
mse1=mean_squared_error(y_test,y_pred)
rmse=mse1**(1/2)
print(rmse)
# Code ends here

# import libraries
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.linear_model import Ridge,Lasso

# regularization parameters for grid search
ridge_lambdas = [0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6, 10, 30, 60]
lasso_lambdas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1]

# Code starts here
ridge_model=Ridge()
ridge_grid=GridSearchCV(estimator=ridge_model, param_grid=dict(alpha=ridge_lambdas))
ridge_grid.fit(X_train,y_train)
lasso_model=Lasso()
lasso_grid=GridSearchCV(estimator=lasso_model, param_grid=dict(alpha=lasso_lambdas))
lasso_grid.fit(X_train,y_train)
pre_grid=ridge_grid.predict(X_test)
pre_lasso=lasso_grid.predict(X_test)
ridge_rmse=np.sqrt(mean_squared_error(y_test,pre_grid))
lasso_rmse=np.sqrt(mean_squared_error(y_test,pre_lasso))
print(ridge_rmse)
print(lasso_rmse)
# Code ends here
