#Task 1 - Data Cleaning
# Import Libraries
import os
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# Code starts here
df = pd.read_csv(path)
df.columns = map(str.lower, df.columns)
df.columns = df.columns.str.replace(' ', '_')
df.replace('NaN',np.nan)


# Code ends here

#Task 2 - Handling Time Stamp data
from sklearn.model_selection import train_test_split
df.set_index(keys='serial_number',inplace=True,drop=True)


# Code starts
df['established_date']=pd.to_datetime(df['established_date'])
df['acquired_date']=pd.to_datetime(df['acquired_date'])
y=df['2016_deposits']
X=df.drop('2016_deposits',axis=1)
X_train,X_val,y_train,y_val = train_test_split(X,y,test_size = 0.25 , random_state = 3)
# Code ends here

#Task 3 - Generate a feature of age of funds from inception date
# time_col = X_train.select_dtypes(exclude=[np.number,'O']).columns
time_col = ['established_date', 'acquired_date']

# Code starts here

for i in time_col:
    new_col_name="since_"+i
    X_train[new_col_name]=pd.datetime.now() - X_train[i]
    X_train[new_col_name]=X_train[new_col_name]/np.timedelta64(1,'Y')
    X_val[new_col_name]=pd.datetime.now() - X_val[i]
    X_val[new_col_name]=X_val[new_col_name]/np.timedelta64(1,'Y')
X_train.drop(time_col,axis=1,inplace=True)
X_val.drop(time_col,axis=1,inplace=True)
print(X_train['since_established_date'][100])
# Code ends here

#Task 4 - Encoding and filling missing values
from sklearn.preprocessing import LabelEncoder
cat = X_train.select_dtypes(include='O').columns.tolist()
print(cat)
# Code starts here

# Missing values

X_train = X_train.fillna(0)
X_val = X_val.fillna(0)

# Label encoding

le = LabelEncoder()

for x in cat:
    
    X_train[x] = le.fit_transform(X_train[x])
    X_val[x] = le.fit_transform(X_val[x])
    
# One hot encoding

X_train_temp = pd.get_dummies(data = X_train, columns = cat)
X_val_temp = pd.get_dummies(data = X_val, columns = cat)

# Shape of train and test data
print(X_train_temp.head(),X_train.head())

#Task 5 - Decision Tree
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error

# Code starts here
dt = DecisionTreeRegressor(random_state=5)
dt.fit(X_train,y_train)
accuracy=dt.score(X_val,y_val)
print(accuracy)
y_pred=dt.predict(X_val)
mse=mean_squared_error(y_val,y_pred)
rmse=np.sqrt(mse)
print(rmse)

from xgboost import XGBRegressor


# Code starts here
xgb= XGBRegressor(max_depth=50, learning_rate=0.83 , n_estimators=100)
xgb.fit(X_train,y_train)
accuracy=xgb.score(X_val,y_val)
print(accuracy)
y_pred=xgb.predict(X_val)
mse=mean_squared_error(y_val,y_pred)
rmse=np.sqrt(mse)
print(rmse)

# Code ends here
